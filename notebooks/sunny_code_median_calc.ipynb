{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import SparkSession\n",
    "from pysparkling import *\n",
    "import os\n",
    "import getpass\n",
    "import pandas as pd\n",
    "import csv\n",
    "import us\n",
    "import h2o\n",
    "import pyspark.sql.functions as sf\n",
    "from pyspark.sql.window import Window\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['PYSPARK_SUBMIT_ARGS'] = '--packages \"org.apache.hadoop:hadoop-aws:2.7.4\" pyspark-shell'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connecting to H2O server at http://10.1.150.140:54323 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div style=\"overflow:auto\"><table style=\"width:50%\"><tr><td>H2O cluster uptime:</td>\n",
       "<td>12 secs</td></tr>\n",
       "<tr><td>H2O cluster timezone:</td>\n",
       "<td>America/Los_Angeles</td></tr>\n",
       "<tr><td>H2O data parsing timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O cluster version:</td>\n",
       "<td>3.28.0.1</td></tr>\n",
       "<tr><td>H2O cluster version age:</td>\n",
       "<td>30 days </td></tr>\n",
       "<tr><td>H2O cluster name:</td>\n",
       "<td>sparkling-water-skwong_local-1579214248571</td></tr>\n",
       "<tr><td>H2O cluster total nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O cluster free memory:</td>\n",
       "<td>910 Mb</td></tr>\n",
       "<tr><td>H2O cluster total cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster allowed cores:</td>\n",
       "<td>12</td></tr>\n",
       "<tr><td>H2O cluster status:</td>\n",
       "<td>accepting new members, healthy</td></tr>\n",
       "<tr><td>H2O connection url:</td>\n",
       "<td>http://10.1.150.140:54323</td></tr>\n",
       "<tr><td>H2O connection proxy:</td>\n",
       "<td>None</td></tr>\n",
       "<tr><td>H2O internal security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>H2O API Extensions:</td>\n",
       "<td>XGBoost, Algos, Amazon S3, AutoML, Core V3, TargetEncoder, Core V4</td></tr>\n",
       "<tr><td>Python version:</td>\n",
       "<td>3.7.4 final</td></tr></table></div>"
      ],
      "text/plain": [
       "--------------------------  ------------------------------------------------------------------\n",
       "H2O cluster uptime:         12 secs\n",
       "H2O cluster timezone:       America/Los_Angeles\n",
       "H2O data parsing timezone:  UTC\n",
       "H2O cluster version:        3.28.0.1\n",
       "H2O cluster version age:    30 days\n",
       "H2O cluster name:           sparkling-water-skwong_local-1579214248571\n",
       "H2O cluster total nodes:    1\n",
       "H2O cluster free memory:    910 Mb\n",
       "H2O cluster total cores:    12\n",
       "H2O cluster allowed cores:  12\n",
       "H2O cluster status:         accepting new members, healthy\n",
       "H2O connection url:         http://10.1.150.140:54323\n",
       "H2O connection proxy:\n",
       "H2O internal security:      False\n",
       "H2O API Extensions:         XGBoost, Algos, Amazon S3, AutoML, Core V3, TargetEncoder, Core V4\n",
       "Python version:             3.7.4 final\n",
       "--------------------------  ------------------------------------------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sparkling Water Context:\n",
      " * Sparkling Water Version: 3.28.0.1-1-2.4\n",
      " * H2O name: sparkling-water-skwong_local-1579214248571\n",
      " * cluster size: 1\n",
      " * list of used nodes:\n",
      "  (executorId, host, port)\n",
      "  ------------------------\n",
      "  (driver,10.1.150.140,54323)\n",
      "  ------------------------\n",
      "\n",
      "  Open H2O Flow in browser: http://10.1.150.140:54323 (CMD + click in Mac OSX)\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "sc = SparkContext.getOrCreate()\n",
    "ss = SparkSession.builder.getOrCreate()\n",
    "hc = H2OContext.getOrCreate(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "········\n"
     ]
    }
   ],
   "source": [
    "access_key = 'AKIAWOHFNKOOOHDEROZ4'\n",
    "secret_key = getpass.getpass()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc._jsc.hadoopConfiguration().set(\"fs.s3.impl\", \"org.apache.hadoop.fs.s3a.S3AFileSystem\")\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.access.key', access_key)\n",
    "sc._jsc.hadoopConfiguration().set('fs.s3a.secret.key', secret_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def median_by_state(data, median_col):\n",
    "    '''\n",
    "    Gather the Median by state for a table that has a median by state and county\n",
    "    data - the csv data set that is used from the census\n",
    "    median_col - the column we want to median by state for\n",
    "    '''\n",
    "    # Gets coluns needed in order to do the median by state\n",
    "    data_reduced = data.select(['State','County','TotalPop',median_col])\n",
    "    \n",
    "    #Gets the cumulative sum\n",
    "    data_reduced_w_cum_sum = data_reduced.orderBy(['State',median_col,'TotalPop'])\\\n",
    "                  .withColumn('cumsum_total',sf.sum(data_reduced.TotalPop)\\\n",
    "                              .over(Window.partitionBy('State')\\\n",
    "                              .rowsBetween(-sys.maxsize, 0)))\\\n",
    "                 .withColumn('state_total_pop',sf.sum(data_reduced.TotalPop)\\\n",
    "                              .over(Window.partitionBy('State')))\n",
    "    \n",
    "    # Gets median population\n",
    "    final_table = data_reduced_w_cum_sum\\\n",
    "                         .withColumn('median_pop',sf.ceil(data_reduced_w_cum_sum['state_total_pop']/2))\n",
    "    \n",
    "    #gets the median of every state\n",
    "    final_table = final_table\\\n",
    "                 .withColumn('marker',final_table['median_pop'] >= final_table['cumsum_total'])\n",
    "    final_table = final_table\\\n",
    "                 .withColumn('marker2',sf.lag(final_table['marker'])\\\n",
    "                             .over(Window.partitionBy('State').orderBy(['State','cumsum_total'])))\n",
    "    final_table = final_table.filter((final_table['marker']==False) & (final_table['marker2']==True)).\\\n",
    "                select(['State',median_col])\n",
    "    \n",
    "    return final_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+-------+\n",
      "|       State| Income|\n",
      "+------------+-------+\n",
      "|        Utah|62117.0|\n",
      "|      Hawaii|74460.0|\n",
      "|   Minnesota|65834.0|\n",
      "|        Ohio|49013.0|\n",
      "|    Arkansas|41268.0|\n",
      "|      Oregon|51223.0|\n",
      "|       Texas|54457.0|\n",
      "|North Dakota|54559.0|\n",
      "|Pennsylvania|53040.0|\n",
      "| Connecticut|66395.0|\n",
      "|    Nebraska|52250.0|\n",
      "|     Vermont|53869.0|\n",
      "|      Nevada|51575.0|\n",
      "| Puerto Rico|18609.0|\n",
      "|  Washington|60756.0|\n",
      "|    Illinois|55251.0|\n",
      "|    Oklahoma|47437.0|\n",
      "|    Delaware|65476.0|\n",
      "|      Alaska|72983.0|\n",
      "|  New Mexico|47725.0|\n",
      "+------------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "med_income_by_state = ss.read.csv(\"s3a://msds-durian-candy/census/acs2015_county_data.csv.gz\", header=True)\n",
    "median_by_state(med_income_by_state,'Income').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+------+\n",
      "|       State|Income|\n",
      "+------------+------+\n",
      "|        Utah| 67922|\n",
      "|      Hawaii| 80078|\n",
      "|   Minnesota| 71154|\n",
      "|        Ohio| 52389|\n",
      "|    Arkansas| 43504|\n",
      "|      Oregon| 58392|\n",
      "|       Texas| 57791|\n",
      "|North Dakota| 58767|\n",
      "|Pennsylvania| 56702|\n",
      "| Connecticut| 69936|\n",
      "|    Nebraska| 55875|\n",
      "|     Vermont| 56828|\n",
      "|      Nevada| 54882|\n",
      "| Puerto Rico| 18900|\n",
      "|  Washington| 67832|\n",
      "|    Illinois| 59426|\n",
      "|    Oklahoma| 50762|\n",
      "|    Delaware| 68336|\n",
      "|      Alaska| 76250|\n",
      "|  New Mexico| 50386|\n",
      "+------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "med_income_by_state = ss.read.csv(\"s3a://msds-durian-candy/census/acs2017_county_data.csv.gz\", header=True)\n",
    "median_by_state(med_income_by_state,'Income').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
